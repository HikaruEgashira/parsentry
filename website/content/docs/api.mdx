---
title: API Reference
description: Complete command-line interface and library API reference for Vulnhuntrs
---

import { Tabs, Tab } from 'fumadocs-ui/components/tabs'
import { Callout } from 'fumadocs-ui/components/callout'

# API Reference

Complete reference for Vulnhuntrs command-line interface and library usage.

## Command Line Interface

### Basic Usage

```bash
vulnhuntrs [OPTIONS] [COMMAND]
```

### Commands

#### Analyze Repository
```bash
vulnhuntrs -r <PATH>
vulnhuntrs --repo <REPOSITORY>
```

#### Analyze Single File
```bash
vulnhuntrs -a <FILE>
vulnhuntrs --analyze <FILE>
```

### Global Options

#### Required Options

| Option | Short | Description | Example |
|--------|-------|-------------|---------|
| `--repo <PATH>` | `-r` | Analyze local directory | `-r ./src` |
| `--analyze <FILE>` | `-a` | Analyze single file | `-a main.py` |
| `--repo <OWNER/REPO>` | | Analyze GitHub repository | `--repo OWASP/WebGoat` |

<Callout type="info">
  You must specify exactly one of: `-r`, `-a`, or `--repo` for GitHub analysis.
</Callout>

#### Model Configuration

| Option | Description | Default | Example |
|--------|-------------|---------|---------|
| `--model <MODEL>` | LLM model to use | Auto-detect from API key | `--model gpt-4-turbo` |

**Supported Models**:

<Tabs items={['OpenAI', 'Anthropic', 'Google']}>
  <Tab value="OpenAI">
    - `gpt-4-turbo` (recommended)
    - `gpt-4`
    - `gpt-3.5-turbo`
    - `gpt-4-1106-preview`
  </Tab>
  <Tab value="Anthropic">
    - `claude-3-sonnet-20240229` (recommended)
    - `claude-3-haiku-20240307`
    - `claude-3-opus-20240229`
  </Tab>
  <Tab value="Google">
    - `gemini-pro`
    - `gemini-pro-vision`
  </Tab>
</Tabs>

#### Filtering Options

| Option | Description | Default | Example |
|--------|-------------|---------|---------|
| `--min-confidence <LEVEL>` | Minimum confidence score (0-10) | `0` | `--min-confidence 7` |
| `--vuln-types <TYPES>` | Comma-separated vulnerability types | All types | `--vuln-types RCE,SQLI` |

**Vulnerability Types**:
- `RCE` - Remote Code Execution
- `SQLI` - SQL Injection  
- `XSS` - Cross-Site Scripting
- `IDOR` - Insecure Direct Object Reference
- `LFI` - Local File Inclusion
- `RFI` - Remote File Inclusion
- `XXE` - XML External Entity
- `SSRF` - Server-Side Request Forgery
- `CSRF` - Cross-Site Request Forgery

#### Output Options

| Option | Description | Default | Example |
|--------|-------------|---------|---------|
| `--output-dir <DIR>` | Directory for detailed reports | None | `--output-dir ./reports` |
| `--summary` | Generate summary report | `false` | `--summary` |
| `--verbose` / `-v` | Verbose output | `false` | `-v` |
| `--verbose` / `-vv` | Extra verbose output | `false` | `-vv` |

#### File Filtering

| Option | Description | Example |
|--------|-------------|---------|
| `--exclude-dirs <DIRS>` | Comma-separated directories to exclude | `--exclude-dirs node_modules,target` |
| `--include-patterns <PATTERNS>` | Comma-separated file patterns to include | `--include-patterns "*.py,*.js"` |

### Complete Examples

#### Basic Analysis
```bash
# Analyze current directory with default settings
vulnhuntrs -r .

# Analyze with high confidence filter
vulnhuntrs -r . --min-confidence 8

# Generate detailed reports
vulnhuntrs -r . --output-dir ./security-reports --summary
```

#### Advanced Filtering
```bash
# Focus on critical vulnerability types
vulnhuntrs -r . --vuln-types RCE,SQLI --min-confidence 7

# Exclude common directories and focus on source files
vulnhuntrs -r . \
  --exclude-dirs "node_modules,target,vendor" \
  --include-patterns "*.py,*.js,*.go,*.rs"
```

#### Model-Specific Analysis
```bash
# Use specific models for different accuracy/speed tradeoffs
vulnhuntrs -r . --model gpt-4-turbo --min-confidence 8
vulnhuntrs -r . --model claude-3-haiku-20240307 --min-confidence 6
vulnhuntrs -r . --model gemini-pro --summary
```

#### GitHub Repository Analysis
```bash
# Analyze public repositories
vulnhuntrs --repo OWASP/WebGoat --min-confidence 7
vulnhuntrs --repo PentesterLab/cr-go --output-dir ./reports

# With filtering
vulnhuntrs --repo yourusername/your-repo \
  --vuln-types XSS,CSRF,SQLI \
  --min-confidence 6
```

## Library API (Rust)

For integrating Vulnhuntrs into Rust applications:

### Core Types

```rust
use vulnhuntrs::{VulnerabilityAnalyzer, Repository, AnalysisConfig};

// Configuration
pub struct AnalysisConfig {
    pub model: String,
    pub min_confidence: u8,
    pub vuln_types: Vec<VulnerabilityType>,
    pub output_dir: Option<PathBuf>,
}

// Main analyzer
pub struct VulnerabilityAnalyzer {
    config: AnalysisConfig,
    client: genai::Client,
}

// Repository representation
pub struct Repository {
    pub path: PathBuf,
    pub files: Vec<SourceFile>,
}
```

### Basic Usage

```rust
use vulnhuntrs::{VulnerabilityAnalyzer, AnalysisConfig, VulnerabilityType};
use std::path::PathBuf;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Configure analysis
    let config = AnalysisConfig {
        model: "gpt-4-turbo".to_string(),
        min_confidence: 7,
        vuln_types: vec![
            VulnerabilityType::RCE,
            VulnerabilityType::SQLI,
        ],
        output_dir: Some(PathBuf::from("./reports")),
    };
    
    // Create analyzer
    let analyzer = VulnerabilityAnalyzer::new(config).await?;
    
    // Analyze repository
    let results = analyzer.analyze_repository("./src").await?;
    
    // Process results
    for result in results {
        println!("Found {} vulnerabilities in {}", 
                 result.vulnerabilities.len(), 
                 result.file_path);
    }
    
    Ok(())
}
```

### Advanced Usage

```rust
use vulnhuntrs::*;

async fn custom_analysis() -> Result<(), AnalysisError> {
    // Custom repository setup
    let mut repo = Repository::new("./project")?;
    repo.exclude_dirs(&["node_modules", "target"]);
    repo.include_patterns(&["*.py", "*.js"]);
    repo.discover_files()?;
    
    // Pattern-based pre-filtering
    let patterns = SecurityPatterns::load("security_patterns/patterns.yml")?;
    let matched_files = patterns.filter_files(&repo.files);
    
    // Custom analyzer configuration
    let config = AnalysisConfig::builder()
        .model("claude-3-sonnet-20240229")
        .min_confidence(6)
        .vuln_types(&[VulnerabilityType::XSS, VulnerabilityType::CSRF])
        .parallel_analysis(true)
        .build();
        
    let analyzer = VulnerabilityAnalyzer::new(config).await?;
    
    // Analyze with custom context
    let mut results = Vec::new();
    for file in matched_files {
        let context = analyzer.build_context(&file, &repo).await?;
        let result = analyzer.analyze_with_context(&file, &context).await?;
        results.push(result);
    }
    
    // Generate custom reports
    let report_generator = ReportGenerator::new();
    report_generator.generate_markdown(&results, "./custom-report.md")?;
    report_generator.generate_json(&results, "./results.json")?;
    
    Ok(())
}
```

## Response Format

### Analysis Result

```rust
#[derive(Debug, Serialize, Deserialize)]
pub struct AnalysisResult {
    pub file_path: String,
    pub vulnerabilities: Vec<Vulnerability>,
    pub analysis_notes: String,
    pub metadata: AnalysisMetadata,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct Vulnerability {
    pub vulnerability_type: VulnerabilityType,
    pub description: String,
    pub confidence: u8,
    pub poc: Option<String>,
    pub line_number: Option<usize>,
    pub function_name: Option<String>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct AnalysisMetadata {
    pub model: String,
    pub timestamp: String,
    pub analysis_duration: Duration,
    pub token_usage: Option<TokenUsage>,
}
```

### JSON Output Example

```json
{
  "file_path": "src/auth.py",
  "vulnerabilities": [
    {
      "vulnerability_type": "SQLI",
      "description": "SQL injection vulnerability in login function",
      "confidence": 9,
      "poc": "username=' OR '1'='1' --",
      "line_number": 45,
      "function_name": "authenticate_user"
    }
  ],
  "analysis_notes": "High confidence SQL injection found. User input directly embedded in SQL query without parameterization.",
  "metadata": {
    "model": "gpt-4-turbo",
    "timestamp": "2024-01-15T10:30:45Z",
    "analysis_duration": "2.3s",
    "token_usage": {
      "prompt_tokens": 1250,
      "completion_tokens": 340,
      "total_tokens": 1590
    }
  }
}
```

## Environment Variables

### Required Variables

| Variable | Description | Example |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key for GPT models | `sk-...` |
| `ANTHROPIC_API_KEY` | Anthropic API key for Claude models | `sk-ant-...` |
| `GOOGLE_API_KEY` | Google API key for Gemini models | `...` |

### Optional Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `VULNHUNTRS_MODEL` | Default model to use | Auto-detect |
| `VULNHUNTRS_MIN_CONFIDENCE` | Default minimum confidence | `0` |
| `VULNHUNTRS_OUTPUT_DIR` | Default output directory | None |
| `VULNHUNTRS_PARALLEL` | Enable parallel analysis | `true` |

### Configuration Example

```bash
# Set environment variables
export OPENAI_API_KEY="sk-your-openai-key"
export VULNHUNTRS_MODEL="gpt-4-turbo"
export VULNHUNTRS_MIN_CONFIDENCE="7"
export VULNHUNTRS_OUTPUT_DIR="./security-reports"

# Run with environment configuration
vulnhuntrs -r .
```

## Error Codes

| Exit Code | Description |
|-----------|-------------|
| `0` | Success |
| `1` | General error |
| `2` | Invalid arguments |
| `3` | Authentication error (invalid API key) |
| `4` | Network error |
| `5` | File not found or permission error |
| `6` | Analysis error |
| `7` | Rate limit exceeded |

## Docker API

### Basic Usage

```bash
docker run ghcr.io/hikaruegashira/vulnhuntrs:latest [OPTIONS]
```

### Environment Variables in Docker

```bash
docker run \
  -e OPENAI_API_KEY=$OPENAI_API_KEY \
  -e VULNHUNTRS_MODEL=gpt-4-turbo \
  -v $(pwd):/app \
  -v $(pwd)/reports:/reports \
  ghcr.io/hikaruegashira/vulnhuntrs:latest \
  -r /app --output-dir /reports
```

### Docker Compose

```yaml
version: '3.8'
services:
  vulnhuntrs:
    image: ghcr.io/hikaruegashira/vulnhuntrs:latest
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - .:/app:ro
      - ./reports:/reports
    command: -r /app --output-dir /reports --summary
```

## Performance Metrics

### Typical Analysis Times

| Codebase Size | Files | Time (GPT-4) | Time (Claude-3) |
|---------------|-------|---------------|-----------------|
| Small (< 10 files) | 5-10 | 30-60s | 20-40s |
| Medium (10-100 files) | 25-50 | 2-5 min | 1-3 min |
| Large (100+ files) | 100+ | 10-30 min | 5-15 min |

### Memory Usage

| Codebase Size | Memory Usage | Recommended RAM |
|---------------|--------------|-----------------|
| Small | 50-100 MB | 512 MB |
| Medium | 200-500 MB | 1 GB |
| Large | 1-2 GB | 4 GB |

<Callout type="info">
  Performance varies based on model choice, code complexity, and API response times.
</Callout>

## Rate Limits

### Default Limits by Provider

| Provider | Requests/min | Tokens/min | 
|----------|--------------|------------|
| OpenAI | 3,000 | 250,000 |
| Anthropic | 1,000 | 100,000 |
| Google | 300 | 32,000 |

### Rate Limit Handling

Vulnhuntrs automatically handles rate limits with:
- **Exponential backoff**: Gradually increases wait time
- **Retry logic**: Automatically retries failed requests
- **Progress preservation**: Resumes analysis from last successful file

## Next Steps

- [View configuration examples](/docs/configuration)
- [Explore usage patterns](/docs/examples)
- [Learn about the architecture](/docs/architecture)